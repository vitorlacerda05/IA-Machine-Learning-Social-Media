# ClassificaÃ§Ã£o Supervisionada de Engajamento em Redes Sociais

## ğŸ“‹ DescriÃ§Ã£o

Projeto que implementa e compara **quatro paradigmas de aprendizado de mÃ¡quina** para classificar engajamento de postagens em redes sociais.

### ğŸ¯ Objetivo

Prever se uma postagem terÃ¡ **alto** ou **baixo engajamento** baseado apenas no conteÃºdo textual.

> **RestriÃ§Ã£o:** Durante a inferÃªncia, apenas o conteÃºdo textual pode ser usado.

## ğŸ† Resultado Final

**K-Nearest Neighbors (KNN)** demonstrou ser o melhor modelo, superando o SVM que inicialmente apresentou melhor performance na validaÃ§Ã£o cruzada.

### ğŸ¯ Por que KNN foi o Melhor?

- **Robustez**: Menos propenso a overfitting
- **Similaridade semÃ¢ntica**: Funciona excepcionalmente bem com embeddings
- **Adaptabilidade**: Captura melhor padrÃµes dinÃ¢micos de redes sociais

## ğŸ”¬ Paradigmas Implementados

1. **ProbabilÃ­stico**: Naive Bayes, RegressÃ£o LogÃ­stica
2. **SimbÃ³lico**: Ãrvore de DecisÃ£o, Random Forest
3. **Conexionista**: Rede Neural Multicamadas
4. **EstatÃ­stico**: SVM, KNN â­ **MELHOR**, Gradient Boosting

## ğŸ“ Estrutura do Projeto

```
supervised-classification-of-social-networks/
â”œâ”€â”€ main.py                                # AnÃ¡lise completa dos 4 paradigmas
â”œâ”€â”€ predictionKNN.py                       # Pipeline de prediÃ§Ã£o com KNN
â”œâ”€â”€ requirements.txt                       # DependÃªncias
â”œâ”€â”€ README.md                             # Este arquivo
â”œâ”€â”€ DADOS.md                              # InstruÃ§Ãµes para dados
â”œâ”€â”€ .gitignore                            # Arquivos ignorados
â”œâ”€â”€ results/                              # Pasta com resultados
â””â”€â”€ theory/                               # Pasta com material teÃ³rico
```

**ğŸ“ Arquivos de Dados (nÃ£o incluÃ­dos no repo):**
- `df_social_data_train.pkl` - Dados de treinamento (~8.5MB)
- `df_social_data_test.csv` - Dados de teste (~3.5MB)
- `modelo_knn_engajamento.pkl` - Modelo treinado (~120MB)
- `df_kaggle_knn.csv` - PrediÃ§Ãµes (~100KB)

> **Nota**: Veja `DADOS.md` para instruÃ§Ãµes sobre como obter os dados.

## ğŸš€ Como Usar

### 1. InstalaÃ§Ã£o
```bash
pip install -r requirements.txt
```

### 2. AnÃ¡lise Completa dos Paradigmas
```bash
python main.py
```

### 3. PrediÃ§Ã£o com KNN (Melhor Modelo)
```bash
python predictionKNN.py
```

**SaÃ­das:**
- `modelo_knn_engajamento.pkl` - Modelo treinado
- `df_kaggle_knn.csv` - PrediÃ§Ãµes no formato de submissÃ£o

## ğŸ“Š Formato do CSV de SaÃ­da

| ID  | Engagement |
| --- | ---------- |
| 0   | alto       |
| 1   | baixo      |
| 2   | alto       |
| ... | ...        |

## ğŸ”§ CaracterÃ­sticas TÃ©cnicas

### **Processamento de Texto**
- **Sentence Transformers**: Modelo "all-MiniLM-L6-v2"
- **384 dimensÃµes** de embeddings
- **NormalizaÃ§Ã£o automÃ¡tica** dos textos

### **Modelo KNN Otimizado**
```python
KNeighborsClassifier(
    n_neighbors=3,      # 3 vizinhos mais prÃ³ximos
    metric="cosine",    # DistÃ¢ncia cosseno
    weights="uniform"   # Peso uniforme
)
```

### **ValidaÃ§Ã£o**
- **Stratified Split**: 70% treino, 30% teste
- **Cross-Validation**: 5-fold
- **MÃ©tricas**: AcurÃ¡cia, PrecisÃ£o, Recall, F1-Score

## ğŸ† Por que KNN Superou o SVM?

### **Overfitting do SVM**
- Kernel RBF muito complexo
- SensÃ­vel a outliers
- Pode memorizar dados de treinamento

### **Robustez do KNN**
- Baseado em similaridade semÃ¢ntica
- Menos propenso a overfitting
- Adapta-se dinamicamente aos novos dados

## ğŸ“š ReferÃªncias

- [scikit-learn Supervised Learning](https://scikit-learn.org/stable/supervised_learning.html)
- Sentence Transformers: [Hugging Face](https://huggingface.co/sentence-transformers)

## ğŸ‘¨â€ğŸ’» Autor

**Vitor Antonio de Almeida Lacerda** - NUSP: 12544761  
**Disciplina**: InteligÃªncia Artificial

---

**Nota**: Projeto desenvolvido para a Atividade 1 de IA, focando na comparaÃ§Ã£o dos quatro paradigmas de aprendizado de mÃ¡quina. O KNN demonstrou ser o modelo mais eficaz para classificaÃ§Ã£o de engajamento em redes sociais. 