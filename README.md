# ClassificaÃ§Ã£o Supervisionada de Engajamento em Redes Sociais

## ğŸ“‹ DescriÃ§Ã£o

Projeto que implementa e compara **quatro paradigmas de aprendizado de mÃ¡quina** para classificar engajamento de postagens em redes sociais.

### ğŸ¯ Objetivo

Prever se uma postagem terÃ¡ **alto** ou **baixo engajamento** baseado apenas no conteÃºdo textual.

> **RestriÃ§Ã£o:** Durante a inferÃªncia, apenas o conteÃºdo textual pode ser usado.

## ğŸ† Resultado Final

**K-Nearest Neighbors (KNN)** demonstrou ser o melhor modelo, superando o SVM que inicialmente apresentou melhor performance na validaÃ§Ã£o cruzada.

### ğŸ¯ Por que KNN foi o Melhor?

- **Robustez**: Menos propenso a overfitting
- **Similaridade semÃ¢ntica**: Funciona excepcionalmente bem com embeddings
- **Adaptabilidade**: Captura melhor padrÃµes dinÃ¢micos de redes sociais

## ğŸ”¬ Paradigmas Implementados

1. **ProbabilÃ­stico**: Naive Bayes, RegressÃ£o LogÃ­stica
2. **SimbÃ³lico**: Ãrvore de DecisÃ£o, Random Forest
3. **Conexionista**: Rede Neural Multicamadas
4. **EstatÃ­stico**: SVM, KNN â­ **MELHOR**, Gradient Boosting

## ğŸ“ Estrutura do Projeto

```
supervised-classification-of-social-networks/
â”œâ”€â”€ main.py                                # AnÃ¡lise completa dos 4 paradigmas
â”œâ”€â”€ predictionKNN.py                       # Pipeline de prediÃ§Ã£o com KNN (Supervisionado)
â”œâ”€â”€ predictionKmeans.py                    # Pipeline de clustering com K-Means (NÃ£o Supervisionado)
â”œâ”€â”€ requirements.txt                       # DependÃªncias
â”œâ”€â”€ README.md                             # Este arquivo
â”œâ”€â”€ DADOS.md                              # InstruÃ§Ãµes para dados
â”œâ”€â”€ .gitignore                            # Arquivos ignorados
â”œâ”€â”€ results/                              # Pasta com resultados
â””â”€â”€ theory/                               # Pasta com material teÃ³rico
```

**ğŸ“ Arquivos de Dados (nÃ£o incluÃ­dos no repo):**
- `df_social_data_train.pkl` - Dados de treinamento (~8.5MB)
- `df_social_data_test.csv` - Dados de teste (~3.5MB)
- `modelo_knn_engajamento.pkl` - Modelo KNN treinado (~120MB)
- `modelo_kmeans_engajamento.pkl` - Modelo K-Means treinado (~120MB)
- `df_kaggle_knn.csv` - PrediÃ§Ãµes KNN (~100KB)
- `df_kaggle_kmeans.csv` - Clusters K-Means (~100KB)

> **Nota**: Veja `DADOS.md` para instruÃ§Ãµes sobre como obter os dados.

## ğŸš€ Como Usar

### 1. InstalaÃ§Ã£o
```bash
pip install -r requirements.txt
```

### 2. AnÃ¡lise Completa dos Paradigmas
```bash
python main.py
```

### 3. PrediÃ§Ã£o com KNN (Supervisionado - Melhor Modelo)
```bash
python predictionKNN.py
```

**SaÃ­das:**
- `modelo_knn_engajamento.pkl` - Modelo treinado
- `df_kaggle_knn.csv` - PrediÃ§Ãµes no formato de submissÃ£o

### 4. Clustering com K-Means (NÃ£o Supervisionado)
```bash
python predictionKmeans.py
```

**SaÃ­das:**
- `modelo_kmeans_engajamento.pkl` - Modelo treinado
- `df_kaggle_kmeans.csv` - Clusters no formato de submissÃ£o

## ğŸ“Š Formato do CSV de SaÃ­da

### KNN (Supervisionado)
| ID  | Engagement |
| --- | ---------- |
| 0   | alto       |
| 1   | baixo      |
| 2   | alto       |
| ... | ...        |

### K-Means (NÃ£o Supervisionado)
| ID  | Engagement |
| --- | ---------- |
| 0   | 3          |
| 1   | 7          |
| 2   | 12         |
| ... | ...        |

> **Nota**: No K-Means, "Engagement" representa o nÃºmero do cluster (0-14), nÃ£o categorias de engajamento.

## ğŸ”§ CaracterÃ­sticas TÃ©cnicas

### **Processamento de Texto**
- **Sentence Transformers**: Modelo "all-MiniLM-L6-v2"
- **384 dimensÃµes** de embeddings
- **NormalizaÃ§Ã£o automÃ¡tica** dos textos

### **Modelo KNN Otimizado (Supervisionado)**
```python
KNeighborsClassifier(
    n_neighbors=3,      # 3 vizinhos mais prÃ³ximos
    metric="cosine",    # DistÃ¢ncia cosseno
    weights="uniform"   # Peso uniforme
)
```

### **Modelo K-Means (NÃ£o Supervisionado)**
```python
KMeans(
    n_clusters=15,      # 15 clusters
    random_state=0,     # Reproduzibilidade
    n_init=10          # 10 inicializaÃ§Ãµes
)
```

### **ValidaÃ§Ã£o**
- **Stratified Split**: 70% treino, 30% teste
- **Cross-Validation**: 5-fold
- **MÃ©tricas**: AcurÃ¡cia, PrecisÃ£o, Recall, F1-Score

## ğŸ† Por que KNN Superou o SVM?

### **Overfitting do SVM**
- Kernel RBF muito complexo
- SensÃ­vel a outliers
- Pode memorizar dados de treinamento

### **Robustez do KNN**
- Baseado em similaridade semÃ¢ntica
- Menos propenso a overfitting
- Adapta-se dinamicamente aos novos dados

## ğŸ” ComparaÃ§Ã£o: Supervisionado vs NÃ£o Supervisionado

### **KNN (Supervisionado)**
- âœ… Usa labels de treinamento
- âœ… Prediz categorias especÃ­ficas (alto/baixo)
- âœ… MÃ©tricas de avaliaÃ§Ã£o claras
- âœ… Melhor para classificaÃ§Ã£o direta

### **K-Means (NÃ£o Supervisionado)**
- âœ… Descobre padrÃµes ocultos
- âœ… Agrupa por similaridade textual
- âœ… NÃ£o precisa de labels prÃ©vios
- âœ… Ãštil para anÃ¡lise exploratÃ³ria

## ğŸ“š ReferÃªncias

- [scikit-learn Supervised Learning](https://scikit-learn.org/stable/supervised_learning.html)
- Sentence Transformers: [Hugging Face](https://huggingface.co/sentence-transformers)

## ğŸ‘¨â€ğŸ’» Autor

**Vitor Antonio de Almeida Lacerda** - NUSP: 12544761  
**Disciplina**: InteligÃªncia Artificial

---

**Nota**: Projeto desenvolvido para a Atividade 1 de IA, focando na comparaÃ§Ã£o dos quatro paradigmas de aprendizado de mÃ¡quina. O KNN demonstrou ser o modelo mais eficaz para classificaÃ§Ã£o de engajamento em redes sociais. TambÃ©m inclui implementaÃ§Ã£o de K-Means para anÃ¡lise nÃ£o supervisionada. 